import numpy as np

from scipy import stats

import pymc3 as pm


def from_posterior(param, samples):
    """Utility fucntion for generating a PyMC3 distribution
    from a set of empircal sample (the trace provided by MCMC).

    This is dirty hack which mostly work for univariate distibutions
    enforcing a strong normality assumption on both prior and posterior.

    See issues in PyMC3 and Stan:

        * https://discourse.pymc.io/t/can-traces-be-used-as-priors/3438/2
        * https://discourse.mc-stan.org/t/composing-stan-
          models-posterior-as-next-prior/8093

    Args:
        param:: string, name of the parameter for which the
            prior is generated (through interpolation).
        samples: numpy array, samples from the posetrior that
            we want use for generating new priors.

    Returns:
        Interpolated: pymc3 continuous distribution, distribution generated
        interpolating
            the samples.
    """
    smin, smax = np.min(samples), np.max(samples)
    width = smax - smin
    x = np.linspace(smin, smax, 1000)
    y = stats.gaussian_kde(samples)(x)

    # what was never sampled should have a small probability but not 0,
    # so we'll extend the domain and use linear approximation of density on it
    x = np.concatenate(
        [
            [x[0] - 3 * width],
            x,
            [x[-1] + 3 * width]
        ]
    )
    y = np.concatenate(
        [
            [0],
            y,
            [0]
        ]
    )
    return pm.Interpolated(param, x, y)


def binomial(obs, n, posterior_theta=None, **normal_kwargs):
    """Model for estimating the proportion of conversions for two branches.
    It uses a beta binomial model estimating the proportion of the first
    branch, the second one is derived as complementary.

    Args:
        - obs: a numpy array, observations of the beta binomial model.
        - n: integer, number of trials that generated obs.
        - posterior: pymc3 interpolated distribution, posterior for the
            parameter p generated by the previous iteration.
        - normal_kwargs: keyword arguments, args of a pymc3 normal
            distribution.

    Returns:
        - model: a PyMC3 beta-binomial model.
    """
    with pm.Model() as model:

        if posterior_theta is None:
            theta = pm.Normal(
                'theta',
                **normal_kwargs
            )
        else:
            theta = from_posterior(
                'theta',
                posterior_theta
            )

        p = pm.Deterministic(
            'p',
            pm.math.sigmoid(theta)
        )

        observed = pm.Binomial(
            'observed_conversion',
            p=p,
            n=n,
            observed=obs
        )

    return model


def thompson_sampler_simulation(ps_1, ps_2, initial_alloc=0.5,
                                sample_size=1000, update_resources=True,
                                epsilon=0.1):
    """Procedure for simulating thompson sampling procedure given a
    sequence of probabilities.

    When updated resources is set to False, the procedure is equivalent
    to connventional AB test (although sequential) with equal groups size.

    We can control exploration / exploitation sampling at random from the
    posterior distribution and allowin for epsilon chance of 50-50 allocation.

    Args:
        - ps_1: iterable of floats, probability of converions
            for branch 1 at different times.
        - ps_2: iterable of floats, probability of converions
            for branch 2 at different times.
        - initial_alloc: float, proportion of total resources allocated
            to branch 1 at the start of the simulation.
        - sample_size: int, total number of resources to beallocated at
            any given time.
        - update_resources: bool, wheteher we do automatic resources allocation
            based on which of the two branches is generating more conversions.
        - epsilon: a float, random noise paramter determining the probability
            to switch off the automatic resources allocation and do balanced
            allocation.

    Returns:
        - alloc_history: iterable of float, percentage of resources allocated
            to branch 1 at any given time.
        - total_conversions_history: iterable of int, total number of
            conversions at any given time.
        - estimates_p_history: iterable of numpy array, the estimated
            probability of generating conversion for branch 1 at any given
            time.
    """
    alloc_history = []
    estimates_p_history = []
    total_conversions_history = []
    alloc = initial_alloc
    trace = None
    for day, (p_1, p_2) in enumerate(zip(ps_1, ps_2)):

        n_1 = int(sample_size * (alloc))
        n_2 = int(sample_size - n_1)

        obs_1 = np.random.binomial(
                    p=p_1,
                    n=n_1
                )
        obs_2 = np.random.binomial(
                    p=p_2,
                    n=n_2
                )

        if day == 0:
            model = binomial(
                obs=obs_1,
                n=obs_1 + obs_2,
                mu=0,
                sigma=10
            )
        else:
            model = binomial(
                obs=obs_1,
                n=obs_1 + obs_2,
                posterior_theta=trace['theta']
            )

        with model:
            mean_field = pm.fit(30000)
            trace = mean_field.sample(1000)

        if update_resources:
            if np.random.random() < epsilon:
                alloc = 0.5
            else:
                alloc = np.random.choice(trace['p'])
                alloc = max(.01, min(alloc, .99))

        alloc_history.append(alloc)
        total_conversions_history.append(obs_1 + obs_2)
        estimates_p_history.append(trace['p'])

    return alloc_history, total_conversions_history, estimates_p_history
